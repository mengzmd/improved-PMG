{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:33.108795Z","iopub.execute_input":"2023-02-20T11:41:33.109704Z","iopub.status.idle":"2023-02-20T11:41:34.099363Z","shell.execute_reply.started":"2023-02-20T11:41:33.109590Z","shell.execute_reply":"2023-02-20T11:41:34.097964Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:34.105698Z","iopub.execute_input":"2023-02-20T11:41:34.109303Z","iopub.status.idle":"2023-02-20T11:41:35.224200Z","shell.execute_reply.started":"2023-02-20T11:41:34.109255Z","shell.execute_reply":"2023-02-20T11:41:35.222744Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!cd dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:35.226425Z","iopub.execute_input":"2023-02-20T11:41:35.227153Z","iopub.status.idle":"2023-02-20T11:41:36.411162Z","shell.execute_reply.started":"2023-02-20T11:41:35.227107Z","shell.execute_reply":"2023-02-20T11:41:36.409200Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir dataset/train\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:36.421007Z","iopub.execute_input":"2023-02-20T11:41:36.424509Z","iopub.status.idle":"2023-02-20T11:41:37.565109Z","shell.execute_reply.started":"2023-02-20T11:41:36.424447Z","shell.execute_reply":"2023-02-20T11:41:37.563508Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!mkdir dataset/test","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:37.566876Z","iopub.execute_input":"2023-02-20T11:41:37.567257Z","iopub.status.idle":"2023-02-20T11:41:38.705046Z","shell.execute_reply.started":"2023-02-20T11:41:37.567209Z","shell.execute_reply":"2023-02-20T11:41:38.703641Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport time\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:38.707202Z","iopub.execute_input":"2023-02-20T11:41:38.707907Z","iopub.status.idle":"2023-02-20T11:41:38.714067Z","shell.execute_reply.started":"2023-02-20T11:41:38.707866Z","shell.execute_reply":"2023-02-20T11:41:38.712170Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport os\nimport time\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport time\nimport cv2\nfrom skimage import io, color\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport copy\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:38.716924Z","iopub.execute_input":"2023-02-20T11:41:38.718204Z","iopub.status.idle":"2023-02-20T11:41:41.330762Z","shell.execute_reply.started":"2023-02-20T11:41:38.718156Z","shell.execute_reply":"2023-02-20T11:41:41.329802Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom torchvision import datasets \nimport torchvision.transforms as transforms\n\nsplit = {}\n\ntrain_count = {}\ntest_count  = {} \n\n\nwith open('/kaggle/input/cub-200-2011/CUB_200_2011/classes.txt') as fp:\n   line = fp.readline()\n   while line:\n       line = line.strip()\n       class_id , class_name = line.split(' ')\n       folder_name = class_name.split('.')[0]\n       train_count[folder_name] = 1\n       test_count[folder_name]  = 1\n       os.system('mkdir /kaggle/working/dataset/train/{}'.format('class_' + str(folder_name)))\n       os.system('mkdir /kaggle/working/dataset/test/{}'.format('class_' + str(folder_name)))\n       line = fp.readline()\n\nwith open('/kaggle/input/cub-200-2011/CUB_200_2011/train_test_split.txt') as fp:\n   line = fp.readline()\n   while line:\n       line = line.strip()\n       image_id , image_split = line.split(' ')\n       split[int(image_id)] = 'train' if int(image_split) else 'test'\n       line = fp.readline()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:41.332240Z","iopub.execute_input":"2023-02-20T11:41:41.332878Z","iopub.status.idle":"2023-02-20T11:41:42.975122Z","shell.execute_reply.started":"2023-02-20T11:41:41.332845Z","shell.execute_reply":"2023-02-20T11:41:42.974122Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# !pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:42.979759Z","iopub.execute_input":"2023-02-20T11:41:42.981957Z","iopub.status.idle":"2023-02-20T11:41:42.992571Z","shell.execute_reply.started":"2023-02-20T11:41:42.981920Z","shell.execute_reply":"2023-02-20T11:41:42.991411Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:42.996523Z","iopub.execute_input":"2023-02-20T11:41:42.998790Z","iopub.status.idle":"2023-02-20T11:41:43.091361Z","shell.execute_reply.started":"2023-02-20T11:41:42.998756Z","shell.execute_reply":"2023-02-20T11:41:43.090488Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport os\nimport time\nimport torch.nn as nn\n\nimport torchvision\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport time\nimport cv2\nfrom skimage import io, color\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport copy\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:43.099824Z","iopub.execute_input":"2023-02-20T11:41:43.108737Z","iopub.status.idle":"2023-02-20T11:41:43.116693Z","shell.execute_reply.started":"2023-02-20T11:41:43.108701Z","shell.execute_reply":"2023-02-20T11:41:43.115604Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/cub-200-2011/CUB_200_2011/images.txt') as fp:\n   line = fp.readline()\n   while line:\n       line = line.strip()\n       image_id , image_path = line.split(' ')\n       img_class = image_path.split('.')[0]\n       image_split = split[int(image_id)]\n       full_image_path = r'/kaggle/input/cub-200-2011/CUB_200_2011/images/{}'.format(image_path)\n       if image_split == 'train':\n        iter = train_count[img_class]\n        os.system('cp {} /kaggle/working/dataset/train/class_{}/{}.jpg'.format(full_image_path , img_class , str(iter)))\n        train_count[img_class] += 1\n       else:\n        iter = test_count[img_class]\n        os.system('cp {} /kaggle/working/dataset/test/class_{}/{}.jpg'.format(full_image_path , img_class , str(iter)))\n        test_count[img_class] += 1\n       line = fp.readline()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:41:43.121188Z","iopub.execute_input":"2023-02-20T11:41:43.123842Z","iopub.status.idle":"2023-02-20T11:43:57.135599Z","shell.execute_reply.started":"2023-02-20T11:41:43.123808Z","shell.execute_reply":"2023-02-20T11:43:57.134572Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom  torch.utils.model_zoo import load_url as load_state_dict_from_url\n\n\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\n\n\nmodel_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        if groups != 1 or base_width != 64:\n            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n       \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n   \n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        width = int(planes * (base_width / 64.)) * groups\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n      \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n       \n        if self.downsample is not None:\n            identity = self.downsample(x)\n           \n    \n\n        out += identity\n     \n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n                 norm_layer=None):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None \"\n                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n                                       dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n                                       dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n                                       dilate=replace_stride_with_dilation[2])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n                \n                )\n\n                \n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, previous_dilation, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, dilation=self.dilation,\n                                norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x1 = self.maxpool(x)\n\n        x2 = self.layer1(x1)\n        x3 = self.layer2(x2)\n        x4 = self.layer3(x3)\n        x5 = self.layer4(x4)\n\n        x = self.avgpool(x5)\n        x = x.reshape(x.size(0), -1)\n        x = self.fc(x)\n       \n        return x1, x2, x3, x4, x5\n\n\ndef _resnet(arch, inplanes, planes, pretrained, progress, **kwargs):\n    model = ResNet(inplanes, planes, **kwargs)\n    if pretrained:\n        state_dict = load_state_dict_from_url(model_urls[arch],\n                                              progress=progress)\n        model.load_state_dict(state_dict)\n    return model\n\n\ndef resnet18(pretrained=False, progress=True, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet34(pretrained=False, progress=True, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet50(pretrained=False, progress=True, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet101(pretrained=False, progress=True, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet152(pretrained=False, progress=True, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnext50_32x4d(**kwargs):\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 4\n    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n                   pretrained=False, progress=True, **kwargs)\n\n\ndef resnext101_32x8d(**kwargs):\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n                   pretrained=False, progress=True, **kwargs)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.137081Z","iopub.execute_input":"2023-02-20T11:43:57.137909Z","iopub.status.idle":"2023-02-20T11:43:57.293824Z","shell.execute_reply.started":"2023-02-20T11:43:57.137868Z","shell.execute_reply":"2023-02-20T11:43:57.292771Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n                                nn.ReLU(),\n                                nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.295184Z","iopub.execute_input":"2023-02-20T11:43:57.295582Z","iopub.status.idle":"2023-02-20T11:43:57.307977Z","shell.execute_reply.started":"2023-02-20T11:43:57.295545Z","shell.execute_reply":"2023-02-20T11:43:57.307078Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n    \n\nclass PMG(nn.Module):\n    def __init__(self, model, feature_size, classes_num):\n        super(PMG, self).__init__()\n\n        self.features = model\n        self.max1 = nn.MaxPool2d(kernel_size=56, stride=56)\n        self.max2 = nn.MaxPool2d(kernel_size=28, stride=28)\n        self.max3 = nn.MaxPool2d(kernel_size=14, stride=14)\n        self.num_ftrs = 2048 * 1 * 1\n        self.elu = nn.ELU(inplace=True)\n\n        self.classifier_concat = nn.Sequential(\n            nn.BatchNorm1d(1024 * 3),\n            nn.Linear(1024 * 3, feature_size),\n            nn.BatchNorm1d(feature_size),\n            nn.ELU(inplace=True),\n            nn.Linear(feature_size, classes_num),\n        )\n\n        self.conv_block1 = nn.Sequential(\n            BasicConv(self.num_ftrs//4, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n        )\n        self.classifier1 = nn.Sequential(\n            nn.BatchNorm1d(self.num_ftrs//2),\n            nn.Linear(self.num_ftrs//2, feature_size),\n            nn.BatchNorm1d(feature_size),\n            nn.ELU(inplace=True),\n            nn.Linear(feature_size, classes_num),\n        )\n\n        self.conv_block2 = nn.Sequential(#num_ftrs:2048\n            BasicConv(self.num_ftrs//2, feature_size, kernel_size=1, stride=1, padding=0, relu=True),#(1024,512)\n            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)#(512,1024)\n        )\n        self.classifier2 = nn.Sequential(\n            nn.BatchNorm1d(self.num_ftrs//2),\n            nn.Linear(self.num_ftrs//2, feature_size),\n            nn.BatchNorm1d(feature_size),\n            nn.ELU(inplace=True),\n            nn.Linear(feature_size, classes_num),\n        )\n\n        self.conv_block3 = nn.Sequential(\n            BasicConv(self.num_ftrs, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n        )\n        self.classifier3 = nn.Sequential(\n            nn.BatchNorm1d(self.num_ftrs//2),\n            nn.Linear(self.num_ftrs//2, feature_size),\n            nn.BatchNorm1d(feature_size),\n            nn.ELU(inplace=True),\n            nn.Linear(feature_size, classes_num),\n        )\n\n    def forward(self, x):\n        xf1, xf2, xf3, xf4, xf5 = self.features(x)\n        \n        xl1 = self.conv_block1(xf3)\n        xl2 = self.conv_block2(xf4)\n        xl3 = self.conv_block3(xf5)\n        \n    \n        \n        xl1 = self.max1(xl1)\n \n        xl1 = xl1.view(xl1.size(0), -1)\n        xc1 = self.classifier1(xl1)\n     \n        \n        xl2 = self.max2(xl2)\n        xl2 = xl2.view(xl2.size(0), -1)\n        xc2 = self.classifier2(xl2)\n\n        xl3 = self.max3(xl3)\n        xl3 = xl3.view(xl3.size(0), -1)\n        xc3 = self.classifier3(xl3)\n          \n        x_concat = torch.cat((xl1, xl2, xl3), -1)\n        x_concat = self.classifier_concat(x_concat)\n        return  xc1,xc2, xc3, x_concat\n    \n    \nclass BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n                                 momentum=0.01, affine=True) if bn else None\n        self.ca = ChannelAttention(out_planes)\n        self.sa = SpatialAttention()\n        self.relu = nn.ReLU() if relu else None\n        self.downsample = nn.Sequential(\n                    conv1x1(in_planes,out_planes,1),\n                    nn.BatchNorm2d(out_planes)\n                )\n\n    def forward(self, x):\n        residual = x\n        x = self.conv(x)   \n        \n        if self.bn is not None:\n            x = self.bn(x) \n        x = x * self.ca(x)\n        x = x * self.sa(x)\n        \n        \n        residual = self.downsample(residual)\n       \n        x += residual\n            \n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.309487Z","iopub.execute_input":"2023-02-20T11:43:57.309851Z","iopub.status.idle":"2023-02-20T11:43:57.332821Z","shell.execute_reply.started":"2023-02-20T11:43:57.309815Z","shell.execute_reply":"2023-02-20T11:43:57.331887Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n# from torchsummary import summary\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.334151Z","iopub.execute_input":"2023-02-20T11:43:57.334492Z","iopub.status.idle":"2023-02-20T11:43:57.344601Z","shell.execute_reply.started":"2023-02-20T11:43:57.334435Z","shell.execute_reply":"2023-02-20T11:43:57.343407Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nimport torch\nimport torchvision\nfrom torch.autograd import Variable\nfrom torchvision import transforms, models\nimport torch.nn.functional as F\n\n\n\ndef cosine_anneal_schedule(t, nb_epoch, lr):\n    cos_inner = np.pi * (t % (nb_epoch))  # t - 1 is used when t has 1-based indexing.\n    cos_inner /= (nb_epoch)\n    cos_out = np.cos(cos_inner) + 1\n\n    return float(lr / 2 * cos_out)\n\n\ndef load_model(model_name, pretrain=True, require_grad=True):\n    print('==> Building model..')\n    if model_name == 'resnet50_pmg':\n        net = resnet50(pretrained=pretrain)\n        for param in net.parameters():\n            param.requires_grad = require_grad\n        net = PMG(net, 512, 200)\n\n    return net\n\n#载入加入CBAM的ResNet50模型\n# def load_model(model_name, pretrain=True, require_grad=True):\n#     print('==> Building model..')\n#     if model_name == 'resnet50_pmg':\n#         netb = resnet50_cbam(pretrained=pretrain)#原论文中不进行预训练\n#         for param in net.parameters():\n#             param.requires_grad = require_grad\n#         netb = PMG(net, 512, 200)\n#\n#     return netb\n\n\n# def model_info(model):  # Plots a line-by-line description of a PyTorch model\n#     n_p = sum(x.numel() for x in model.parameters())  # number parameters\n#     n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n#     print('\\n%5s %50s %9s %12s %20s %12s %12s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n#     for i, (name, p) in enumerate(model.named_parameters()):\n#         name = name.replace('module_list.', '')\n#         print('%5g %50s %9s %12g %20s %12.3g %12.3g' % (\n#             i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\n#     print('Model Summary: %g layers, %g parameters, %g gradients\\n' % (i + 1, n_p, n_g))\n\n\ndef jigsaw_generator(images, n):\n    l = []\n    for a in range(n):\n        for b in range(n):\n            l.append([a, b])\n    block_size = 448 // n\n    rounds = n ** 2\n    random.shuffle(l)\n    jigsaws = images.clone()\n    for i in range(rounds):\n        x, y = l[i]\n        temp = jigsaws[..., 0:block_size, 0:block_size].clone()\n        jigsaws[..., 0:block_size, 0:block_size] = jigsaws[..., x * block_size:(x + 1) * block_size,\n                                                y * block_size:(y + 1) * block_size].clone()\n        jigsaws[..., x * block_size:(x + 1) * block_size, y * block_size:(y + 1) * block_size] = temp\n\n    return jigsaws\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.346063Z","iopub.execute_input":"2023-02-20T11:43:57.346636Z","iopub.status.idle":"2023-02-20T11:43:57.359943Z","shell.execute_reply.started":"2023-02-20T11:43:57.346580Z","shell.execute_reply":"2023-02-20T11:43:57.358964Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport os\nfrom PIL import Image\n\nimport logging\nimport random\nimport torch\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.362233Z","iopub.execute_input":"2023-02-20T11:43:57.362552Z","iopub.status.idle":"2023-02-20T11:43:57.369851Z","shell.execute_reply.started":"2023-02-20T11:43:57.362527Z","shell.execute_reply":"2023-02-20T11:43:57.368994Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n\n\n\ndef test(net, criterion, batch_size):\n    net.eval()\n    use_cuda = torch.cuda.is_available()\n    test_loss = 0\n    correct = 0\n    correct_com = 0\n    total = 0\n    idx = 0\n    device = torch.device(\"cuda:0\")\n\n    transform_test = transforms.Compose([\n        transforms.Resize((550, 550)),\n        transforms.CenterCrop(448),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ])\n    testset = torchvision.datasets.ImageFolder(root='/kaggle/working/dataset/test',\n                                               transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        idx = batch_idx\n        if use_cuda:\n            inputs, targets = inputs.to(device), targets.to(device)\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        output_1,output_2, output_3, output_concat= net(inputs)\n        outputs_com =  output_1+output_2 + output_3 + output_concat\n\n        loss = criterion(output_concat, targets)\n\n        test_loss += loss.item()\n        _, predicted = torch.max(output_concat.data, 1)\n        _, predicted_com = torch.max(outputs_com.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n        correct_com += predicted_com.eq(targets.data).cpu().sum()\n\n        if batch_idx % 50 == 0:\n            print('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d) |Combined Acc: %.3f%% (%d/%d)' % (\n            batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, 100. * float(correct_com) / total, correct_com, total))\n            with open('bird/log_test.txt', 'a') as file:\n                file.write('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d) |Combined Acc: %.3f%% (%d/%d)\\n-r-r' % (\n                batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, 100. * float(correct_com) / total, correct_com, total)\n            )\n\n    test_acc = 100. * float(correct) / total\n    test_acc_en = 100. * float(correct_com) / total\n    test_loss = test_loss / (idx + 1)\n\n    return test_acc, test_acc_en, test_loss ","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.371258Z","iopub.execute_input":"2023-02-20T11:43:57.371631Z","iopub.status.idle":"2023-02-20T11:43:57.386193Z","shell.execute_reply.started":"2023-02-20T11:43:57.371575Z","shell.execute_reply":"2023-02-20T11:43:57.385306Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train(nb_epoch, batch_size, store_name, resume=False, start_epoch=0, model_path=None):\n    # setup output\n    exp_dir = store_name\n    try:\n        os.stat(exp_dir)\n    except:\n        os.makedirs(exp_dir)\n\n    use_cuda = torch.cuda.is_available()\n    print(use_cuda)\n\n    # Data\n    print('==> Preparing data..')\n    transform_train = transforms.Compose([\n        transforms.Resize((550, 550)),\n        transforms.RandomCrop(448, padding=8),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ])\n    trainset = torchvision.datasets.ImageFolder(root='/kaggle/working/dataset/train', transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n\n    # Model\n    if resume:\n        net = torch.load(model_path)\n#     else:\n#         net = load_model(model_name='resnet50_pmg', pretrain=True, require_grad=True)\n    netp = torch.nn.DataParallel(net, device_ids=[0])\n\n    # GPU\n    device = torch.device(\"cuda:0\")\n    net.to(device)\n    # cudnn.benchmark = True\n\n    CELoss = nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD([\n        {'params': net.classifier_concat.parameters(), 'lr': 0.002},\n        {'params': net.conv_block1.parameters(), 'lr': 0.002},\n        {'params': net.classifier1.parameters(), 'lr': 0.002},\n        {'params': net.conv_block2.parameters(), 'lr': 0.002},\n        {'params': net.classifier2.parameters(), 'lr': 0.002},\n        {'params': net.conv_block3.parameters(), 'lr': 0.002},\n        {'params': net.classifier3.parameters(), 'lr': 0.002},\n        {'params': net.features.parameters(), 'lr': 0.0002}\n\n    ],\n        momentum=0.9, weight_decay=5e-4)\n\n\n    max_val_acc = 0\n    lr = [0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.0002]\n    for epoch in range(start_epoch, nb_epoch):\n        print('\\nEpoch: %d' % epoch)\n        net.train()\n        train_loss = 0\n        train_loss1 = 0\n        train_loss2 = 0\n        train_loss3 = 0\n        train_loss4 = 0\n        correct = 0\n        total = 0\n        idx = 0\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            idx = batch_idx\n            if inputs.shape[0] < batch_size:\n                continue\n            if use_cuda:\n                inputs, targets = inputs.to(device), targets.to(device)\n            inputs, targets = Variable(inputs), Variable(targets)\n\n            # update learning rate\n            for nlr in range(len(optimizer.param_groups)):\n                optimizer.param_groups[nlr]['lr'] = cosine_anneal_schedule(epoch, nb_epoch, lr[nlr])\n            # 训练的4个步骤输入不同n生成的图片\n            # Step 1\n            optimizer.zero_grad()\n            \n            output_1, _, _, _ = netp(inputs)\n            loss1 = CELoss(output_1, targets) * 1\n            loss1.backward()\n            optimizer.step()\n\n            # Step 2\n            optimizer.zero_grad()\n            inputs2 = jigsaw_generator(inputs, 4) \n            _,output_2, _, _ = netp(inputs2)\n            loss2 = CELoss(output_2, targets) * 1\n            loss2.backward()\n            optimizer.step()\n\n            # Step 3\n            optimizer.zero_grad()\n            inputs3 = jigsaw_generator(inputs, 2) \n            _,_, output_3, _ = netp(inputs3)\n            loss3 = CELoss(output_3, targets) * 1\n            loss3.backward()\n            optimizer.step()\n\n            # Step 4\n            optimizer.zero_grad()\n            _,_, _, output_concat = netp(inputs) \n            concat_loss = CELoss(output_concat, targets) * 2 \n            concat_loss.backward()\n            optimizer.step()\n\n            #  training log\n            _, predicted = torch.max(output_concat.data, 1)\n            total += targets.size(0)\n            correct += predicted.eq(targets.data).cpu().sum()\n\n            train_loss += ( loss1.item()+loss2.item() + loss3.item() + concat_loss.item())\n            train_loss1 += loss1.item()\n            train_loss2 += loss2.item()\n            train_loss3 += loss3.item()\n            train_loss4 += concat_loss.item()\n            \n           \n            \n\n            if batch_idx % 50 == 0:\n                print(\n                    'Step: %d |Loss1: %.5f|  Loss2: %.5f | Loss3: %.5f | Loss_concat: %.5f | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n                    batch_idx,train_loss1 / (batch_idx + 1),  train_loss2 / (batch_idx + 1),\n                    train_loss3 / (batch_idx + 1), train_loss4 / (batch_idx + 1), train_loss / (batch_idx + 1),\n                 100. * float(correct) / total, correct, total))\n\n        train_acc = 100. * float(correct) / total\n        train_loss = train_loss / (idx + 1)\n        with open(exp_dir + '/results_train.txt', 'a') as file:\n            file.write(\n                'Iteration %d | train_acc = %.5f | train_loss = %.5f | Loss1: %.5f | Loss2: %.5f | Loss3: %.5f | Loss_concat: %.5f |\\n' % (\n                epoch, train_acc, train_loss, train_loss1 / (idx + 1),train_loss2 / (idx + 1), train_loss3 / (idx + 1),\n                train_loss4 / (idx + 1)))\n\n        \n        val_acc, val_acc_com, val_loss = test(net, CELoss, 3)\n        if val_acc_com > max_val_acc:\n            max_val_acc = val_acc_com\n            net.cpu()\n            torch.save(net, '/kaggle/working/' + store_name + '/model.pth')\n            net.to(device)\n        with open(exp_dir + '/results_test.txt', 'a') as file:\n            file.write('Iteration %d, test_acc = %.5f, test_acc_combined = %.5f, test_loss = %.6f\\n' % (\n            epoch, val_acc, val_acc_com, val_loss))\n            file.write('max_val_acc=%.5f\\n' % (max_val_acc\n                                               ))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.388669Z","iopub.execute_input":"2023-02-20T11:43:57.389255Z","iopub.status.idle":"2023-02-20T11:43:57.413210Z","shell.execute_reply.started":"2023-02-20T11:43:57.389220Z","shell.execute_reply":"2023-02-20T11:43:57.412251Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train(nb_epoch=200,             # number of epoch\n         batch_size=16,         # batch size\n         store_name='bird',     # folder for output\n         resume=True,          # resume training from checkpoint\n         start_epoch=191,         # the start epoch number when you resume the training\n         model_path='/kaggle/input/model16/model (16).pth'\n     )         # the saved model where you want to resume the training","metadata":{"execution":{"iopub.status.busy":"2023-02-20T11:43:57.414546Z","iopub.execute_input":"2023-02-20T11:43:57.415014Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"True\n==> Preparing data..\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 191\nStep: 0 |Loss1: 0.03998|  Loss2: 0.03134 | Loss3: 0.03091 | Loss_concat: 0.03266 | Loss: 0.135 | Acc: 100.000% (16/16)\nStep: 50 |Loss1: 0.03535|  Loss2: 0.04218 | Loss3: 0.03695 | Loss_concat: 0.03231 | Loss: 0.147 | Acc: 100.000% (816/816)\nStep: 100 |Loss1: 0.03684|  Loss2: 0.04348 | Loss3: 0.03921 | Loss_concat: 0.03356 | Loss: 0.153 | Acc: 100.000% (1616/1616)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2018154368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# resume training from checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m191\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# the start epoch number when you resume the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m          \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/model16/model (16).pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m      )         # the saved model where you want to resume the training\n","\u001b[0;32m/tmp/ipykernel_17/615725391.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nb_epoch, batch_size, store_name, resume, start_epoch, model_path)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# Step 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0minputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjigsaw_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    220\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                                 \u001b[0mper_device_and_dtype_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}}]}